["Lecture 2 - The beauty of numpy and dot product in coding neurons and layers", "Lecture 3 - Coding multiple neural network layers and stacking them together", "Lecture 4 - Implementing the Dense Layer Class in Python", "Lecture 5 - Broadcasting and array summation in Python", "Lecture 6 - Coding Neural Network Activation Functions from scratch", "Lecture 7 - Coding one neural network forward pass in Python (no loss)", "Lecture 8 - Coding the cross entropy loss in Python (from scratch)", "Lecture 9 - Introduction to Optimization in Neural Network training", "Lecture 10 - Partial Derivatives and Gradient in Neural Networks", "Lecture 11 - Understand Chain Rule: The backbone of Neural Networks", "Lecture 12 - Backpropagation from scratch on a single neuron", "Lecture 13 - Backpropagation through an entire layer of neurons: from scratch", "Lecture 14 - Role of matrices in backpropagation", "Lecture 15 - Finding derivatives of inputs in backpropagation and why we need them", "Lecture 16 - Coding Backpropagation building blocks in Python", "Lecture 17 - Backpropagation on the ReLU activation class", "Lecrure 18 - Implementing backpropagation on the cross entropy loss function", "Lecture 1 - Neural Network from Scratch: Coding Neurons and Layers", "20 minutes summary: Building, training and testing neural networks from scratch"]